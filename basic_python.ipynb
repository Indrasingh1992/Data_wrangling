{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'World!']\n",
      "['Hello', 'World!']\n"
     ]
    }
   ],
   "source": [
    "# splitting a string \"literal\" and then printing the result\n",
    "split_world = \"Hello World!\".split()\n",
    "print(split_world)\n",
    "# assigning a string to a variable\n",
    "# then printing the result of calling the `split()` method on it\n",
    "world_msg = \"Hello World!\"\n",
    "print(world_msg.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# the following will produce an error because\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# the `split()` method must be called on a string in order to work!\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43msplit\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello World!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split' is not defined"
     ]
    }
   ],
   "source": [
    "# the following will produce an error because\n",
    "# the `split()` method must be called on a string in order to work!\n",
    "split(\"Hello World!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1662672842.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(5.split())\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# the following will produce an error because\n",
    "# there is no `split()` method for numbers!\n",
    "print(5.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Susan E. McGregor\n",
      "Hello Jeff Bleiel\n"
     ]
    }
   ],
   "source": [
    "# Example 2-6. basic_greeting.py\n",
    "# create a variable named author\n",
    "author = \"Susan E. McGregor\"\n",
    "# create another variable named editor\n",
    "editor  = \"Jeff Bleiel\"\n",
    "# use the built-in print function to output \"Hello\" messages to each person\n",
    "print(\"Hello \"+author)\n",
    "print(\"Hello \"+editor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Susan E. McGregor\n",
      "Hello Jeff Bleiel\n"
     ]
    }
   ],
   "source": [
    "# create a function that prints out a greeting\n",
    "# to any name passed to the function\n",
    "def greet_me(a_name):\n",
    "    print(\"Hello \"+a_name)\n",
    "# create a variable named author\n",
    "author = \"Susan E. McGregor\"\n",
    "# create another variable named editor\n",
    "editor  = \"Jeff Bleiel\"\n",
    "# use my custom function, `greet_me` to output \"Hello\" messages to each person\n",
    "greet_me(author)\n",
    "greet_me(editor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "# Loops \n",
    "# fictional list of chapter page counts\n",
    "page_counts = [28, 32, 44, 23, 56, 32, 12, 34, 30]\n",
    "# variable for tracking total page count; starting value is 0\n",
    "total_pages = 0\n",
    "# for every item in the list, perform some action\n",
    "for a_number in page_counts:\n",
    "# in this case, add the number to our \"total_pages\" variable\n",
    "    total_pages = total_pages + a_number\n",
    "print(total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top of loop!\n",
      "The current item is:\n",
      "28\n",
      "The running total is:\n",
      "28\n",
      "Bottom of loop!\n",
      "Top of loop!\n",
      "The current item is:\n",
      "32\n",
      "The running total is:\n",
      "60\n",
      "Bottom of loop!\n",
      "Top of loop!\n",
      "The current item is:\n",
      "44\n",
      "The running total is:\n",
      "104\n",
      "Bottom of loop!\n",
      "Top of loop!\n",
      "The current item is:\n",
      "23\n",
      "The running total is:\n",
      "127\n",
      "Bottom of loop!\n",
      "Top of loop!\n",
      "The current item is:\n",
      "56\n",
      "The running total is:\n",
      "183\n",
      "Bottom of loop!\n",
      "Top of loop!\n",
      "The current item is:\n",
      "32\n",
      "The running total is:\n",
      "215\n",
      "Bottom of loop!\n",
      "Top of loop!\n",
      "The current item is:\n",
      "12\n",
      "The running total is:\n",
      "227\n",
      "Bottom of loop!\n",
      "Top of loop!\n",
      "The current item is:\n",
      "34\n",
      "The running total is:\n",
      "261\n",
      "Bottom of loop!\n",
      "Top of loop!\n",
      "The current item is:\n",
      "30\n",
      "The running total is:\n",
      "291\n",
      "Bottom of loop!\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "page_counts = [28, 32, 44, 23, 56, 32, 12, 34, 30]\n",
    "# variable for tracking total page count; starting value is 0\n",
    "total_pages = 0\n",
    "# for every item in the list, perform some action\n",
    "for a_number in page_counts:\n",
    "    print(\"Top of loop!\")\n",
    "    print(\"The current item is:\")\n",
    "    print(a_number)\n",
    "    total_pages = total_pages + a_number\n",
    "    print(\"The running total is:\")\n",
    "    print(total_pages)\n",
    "    print(\"Bottom of loop!\")\n",
    "print(total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "# fictional list of chapter page counts\n",
    "page_counts = [28, 32, 44, 23, 56, 32, 12, 34, 30]\n",
    "# `print()` the result of using the `sum()` function on the list \n",
    "print(sum(page_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We can “wrap” our existing code into a new function (here called count_\n",
    "pages()) by indenting one tab and adding the function definition line. <br>\n",
    "2. We have to match the name of the list variable the for loop references to\n",
    "the parameter name provided between the round parentheses in the function\n",
    "definition in. <br>\n",
    "3. A function does not do anything until it is actually called or executed. At this\n",
    "point, we need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "Number of chapters over 30 pages:\n",
      "5\n",
      "Number of chapters under 30 pages:\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# fictional list of chapter page counts\n",
    "page_counts = [28, 32, 44, 23, 56, 32, 12, 34, 30]\n",
    "# create variables to keep track of:\n",
    "# the total pages in the book\n",
    "total_pages = 0\n",
    "# the number of chapters with more than 30 pages,\n",
    "under_30 = 0\n",
    "# the number of chapters with fewer than 30 pages\n",
    "over_30 = 0\n",
    "# for every item in the page_counts list:\n",
    "for a_number in page_counts:\n",
    "    # add the current number of pages to our total_pages count\n",
    "    total_pages = total_pages + a_number\n",
    "    # check if the current number of pages is more than 30\n",
    "    if a_number > 30:\n",
    "        # if so, add 1 to our over_30 counter\n",
    "        over_30 = over_30 + 1\n",
    "    # otherwise...\n",
    "    else:\n",
    "        # add 1 to our under_30 counter\n",
    "        under_30 = under_30 + 1\n",
    "# print our various results\n",
    "print(total_pages)\n",
    "print(\"Number of chapters over 30 pages:\")\n",
    "print(over_30)\n",
    "print(\"Number of chapters under 30 pages:\")\n",
    "print(under_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "Number of chapters over 30 pages:\n",
      "5\n",
      "Number of chapters under 30 pages:\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Example 2-12. page_count_custom_function.py\n",
    " # fictional list of chapter page counts\n",
    "page_counts = [28, 32, 44, 23, 56, 32, 12, 34, 30]\n",
    "# define a new `count_pages()` function that takes one ingredient/argument:\n",
    "# a list of numbers\n",
    "def count_pages(page_count_list):     #1\n",
    "    # create variables to keep track of:\n",
    "    # the total pages in the book\n",
    "    total_pages = 0\n",
    "    # the number of chapters with more than 30 pages,\n",
    "    under_30 = 0\n",
    "    # the number of chapters with fewer than 30 pages\n",
    "    over_30 = 0\n",
    "    # for every item in the page_count_list:\n",
    "    for a_number in page_count_list:     #2\n",
    "        # add the current number of pages to our total_pages count\n",
    "        total_pages = total_pages + a_number\n",
    "        # check if the current number of pages is more than 30\n",
    "        if a_number > 30:\n",
    "            # if so, add 1 to our over_30 counter\n",
    "            over_30 = over_30 + 1\n",
    "        # otherwise...\n",
    "        else:\n",
    "            # add 1 to our under_30 counter\n",
    "            under_30 = under_30 + 1\n",
    "    # print our various results\n",
    "    print(total_pages)\n",
    "    print(\"Number of chapters over 30 pages:\")\n",
    "    print(over_30)\n",
    "    print(\"Number of chapters under 30 pages:\")\n",
    "    print(under_30)\n",
    "    # call/execute this \"recipe\", being sure to pass in our\n",
    "    # actual list as an argument/ingredient\n",
    "count_pages(page_counts)    #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1849979149.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"author\": \"Susan E. McGregor\"\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#  Example 2-13. Introducing an error\n",
    " # although the actual error is on line 4 (missing comma)\n",
    " # the error message points to line 5\n",
    "book = {\"title\":\"Practical Python for Data Wrangling and Data Quality\",\n",
    "\"format\": \"book\"\n",
    "\"author\": \"Susan E. McGregor\"\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m author \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSusan E. McGregor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# pass my `author` variable as the \"ingredient\" to the `greet_me` function\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mgreet_me\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m, in \u001b[0;36mgreet_me\u001b[1;34m(a_name)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreet_me\u001b[39m(a_name):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mA_name\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A_name' is not defined"
     ]
    }
   ],
   "source": [
    "#  Example 2-14. Slightly mismatched variable names will generate runtime errors\n",
    "# create a function that prints out a greeting to any name passed to the function\n",
    "def greet_me(a_name):\n",
    "    print(\"Hello \"+A_name)\n",
    "# create a variable named author\n",
    "author = \"Susan E. McGregor\"\n",
    "# pass my `author` variable as the \"ingredient\" to the `greet_me` function\n",
    "greet_me(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2-15. hitting_the_road_with_citibike.py\n",
    "<br> question: How many Citi Bike rides each day are taken by\n",
    "<br> \"subscribers\" versus \"customers\"?\n",
    "<br> answer: Choose a single day of rides to examine.\n",
    "<br> the dataset used for this exercise was generated from the original\n",
    "<br> Citi Bike system data found here: https://s3.amazonaws.com/tripdata/index.html\n",
    "<br> filename: 202009-citibike-tripdata.csv.zip\n",
    "<br> program Outline:\n",
    "<br> 1. read in the data file: 202009CitibikeTripdataExample.csv\n",
    "<br> 2. create variables to count: subscribers, customers, and other\n",
    "<br> 3. for each row in the file:\n",
    "<br> a. If the \"User Type\" is \"Subscriber,\" add 1 to \"subscriber_count\"\n",
    "<br> b. If the \"User Type\" is \"Customer,\" add 1 to \"customer_count\"\n",
    "<br> c. Otherwise, add 1 to the \"other\" variable\n",
    "<br> 4. print out my results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tripduration', 'starttime', 'stoptime', 'start station id', 'start station name', 'start station latitude', 'start station longitude', 'end station id', 'end station name', 'end station latitude', 'end station longitude', 'bikeid', 'usertype', 'birth year', 'gender']\n",
      "Number of subscribers:\n",
      "35284\n",
      "Number of customers:\n",
      "18549\n",
      "Number of 'other' users:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# import the `csv` library \n",
    "import csv\n",
    "# open the `202009CitibikeTripdataExample.csv` file in read (\"r\") mode\n",
    "# this file should be in the same folder as our Python script or notebook\n",
    "source_file = open(\"JC-202009-citibike-tripdata.csv\",\"r\")\n",
    "# pass our `source_file` as an ingredient to the `csv` library's\n",
    "# DictReader \"recipe\".\n",
    "# store the result in a variable called `citibike_reader`\n",
    "citibike_reader = csv.DictReader(source_file)\n",
    "# the DictReader method has added some useful information to our data,\n",
    "# like a `fieldnames` property that lets us access all the values\n",
    "# in the first or \"header\" row\n",
    "print(citibike_reader.fieldnames)\n",
    "\n",
    "\n",
    "# create a variable to hold the count of each type of Citi Bike user\n",
    "# assign or \"initialize\" each with a value of zero (0)\n",
    "subscriber_count = 0\n",
    "customer_count = 0\n",
    "other_user_count = 0\n",
    "\n",
    "# step 3: loop through every row of our data\n",
    "for a_row in citibike_reader:\n",
    " # step 3a: if the value in the `usertype` column\n",
    "    if a_row[\"usertype\"] == \"Subscriber\":\n",
    "        # add 1 to `subscriber_count`\n",
    "        subscriber_count = subscriber_count +1\n",
    "        # step 3b: otherwise (else), if the value in the `usertype` column\n",
    "        # of the current row is \"Customer\"\n",
    "    elif a_row[\"usertype\"] == \"Customer\":\n",
    "    # add 1 to `subscriber_count`\n",
    "        customer_count = customer_count + 1\n",
    "        # step 3c: the `usertype` value is _neither_\"Subscriber\" nor \"Customer\",\n",
    "        # so we'll add 1 to our catch-all `other_user_count` variable\n",
    "    else:\n",
    "        other_user_count = other_user_count + 1\n",
    "\n",
    "# step 4: print out our results, being sure to include \"labels\" in the process:\n",
    "print(\"Number of subscribers:\")\n",
    "print(subscriber_count)\n",
    "print(\"Number of customers:\")\n",
    "print(customer_count)\n",
    "print(\"Number of 'other' users:\")\n",
    "print(other_user_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data Quality chapter-3\n",
    "\n",
    "what is data quality?<br>\n",
    "data is high quality only if it is both fit for purpose and has\n",
    "high internal integrity.\n",
    "<br> \n",
    "\n",
    "\n",
    "That first concept—the extent to which a given dataset accurately repre‐\n",
    "sents the phenomenon you’re investigating—is broadly what I mean by its fit, and\n",
    "assessing your dataset’s fitness for purpose is much more about applying informed\n",
    "judgment than it is about applying mathematical formulas. The reason for this is\n",
    "quite simple: the world is a messy place, and what may seem like even the simplest\n",
    "data about it is always filtered through some kind of human lens. Take something as\n",
    "straightforward as measuring the temperature in your workspace over the course of a\n",
    "week. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "At its most basic, validity describes the extent to which something measures what it\n",
    "is supposed to. Construct validity describes the extent to which your\n",
    "data measurements effectively capture the (usually abstract) construct, or idea, you’re\n",
    "trying to understand. <br>\n",
    "\n",
    "The other type of validity that is important for data fit is content validity. This type\n",
    "of validity has to do with how complete your data is for a given proxy measurement.\n",
    "<br><br>\n",
    "\n",
    "Within a dataset, the reliability of a given measure describes its accuracy and stability.Together, these help us assess whether the same measure taken twice in the same circumstances will give us the same—or at least very similar—results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Quality has been classified into four different types <br>\n",
    "1. Assessing Data fit:  The extent to which given data set accurately represents the phenomenon we are investigating means data fit. Then assessing data fit is about applying informed judgement than applying mathematical formulas. <br><br>\n",
    "2. Data validity: Extent of measuring what is supposed to be.  Construct validity means extent to which your data measurements are effectively capture. <br><br>\n",
    "3. Reliability: Measurement of data accuracy and stability. <br><br>\n",
    "4. Representativeness: Representativeness of data refers to how well a sample or dataset reflects the population or larger set from which it is drawn. <br><br>\n",
    "5. Assessing Data Integrity: Data integrity is largely about whether the data you have can support the analyses you’ll need to perform in order to answer that question.\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "Improving Data Quality<br>\n",
    "1. Data Cleaning<br><br>\n",
    "2.Data Auguementation: Augmenting a dataset is the process of expanding or elaborating it, usually by connecting it with other datasets—this is really the nature of “big data” in the 21st century. <br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with File Based and Feed Based Data in Pyhton: Chapter 4 <br>\n",
    "\n",
    "Machine Readable: data in a format that can be easily processed by a computer without human intervention while ensuring no semantic meaning is lost. <br><br>\n",
    "\n",
    "Structured data: is any type of data that has been organized and classified in some\n",
    "way, into some version of records and fields. In file-based formats, these are usually\n",
    "rows and columns; in feed-based formats they are often (essentially) lists of objects or dictionaries.<br><br>\n",
    "Unstructured data: Consist of a mash-up of different data types, combining text, numbers, and even photographs or illustrations. The contents of a magazine or a novel, or the waveforms of a song, for example, would typically be considered unstructured data.<br><br><br>\n",
    "\n",
    "### Working with Structured data <br>\n",
    "1. File-Based, Table-Type Data—Take It to Delimit: s delimited files: each data record is on its own line or row, and the boundaries between fields or columns of data values are indicated—or delimited—by a specific text character they are: .csv, .txt, .ods, .xls(x)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tripduration', 'starttime', 'stoptime', 'start station id', 'start station name', 'start station latitude', 'start station longitude', 'end station id', 'end station name', 'end station latitude', 'end station longitude', 'bikeid', 'usertype', 'birth year', 'gender']\n",
      "{'tripduration': '4225', 'starttime': '2020-09-01 00:00:01.0430', 'stoptime': '2020-09-01 01:10:26.6350', 'start station id': '3508', 'start station name': 'St Nicholas Ave & Manhattan Ave', 'start station latitude': '40.809725', 'start station longitude': '-73.953149', 'end station id': '116', 'end station name': 'W 17 St & 8 Ave', 'end station latitude': '40.74177603', 'end station longitude': '-74.00149746', 'bikeid': '44317', 'usertype': 'Customer', 'birth year': '1979', 'gender': '1'}\n",
      "{'tripduration': '1868', 'starttime': '2020-09-01 00:00:04.8320', 'stoptime': '2020-09-01 00:31:13.7650', 'start station id': '3621', 'start station name': '27 Ave & 9 St', 'start station latitude': '40.7739825', 'start station longitude': '-73.9309134', 'end station id': '3094', 'end station name': 'Graham Ave & Withers St', 'end station latitude': '40.7169811', 'end station longitude': '-73.94485918', 'bikeid': '37793', 'usertype': 'Customer', 'birth year': '1991', 'gender': '1'}\n",
      "{'tripduration': '1097', 'starttime': '2020-09-01 00:00:06.8990', 'stoptime': '2020-09-01 00:18:24.2260', 'start station id': '3492', 'start station name': 'E 118 St & Park Ave', 'start station latitude': '40.8005385', 'start station longitude': '-73.9419949', 'end station id': '3959', 'end station name': 'Edgecombe Ave & W 145 St', 'end station latitude': '40.823498', 'end station longitude': '-73.94386', 'bikeid': '41438', 'usertype': 'Subscriber', 'birth year': '1984', 'gender': '1'}\n",
      "{'tripduration': '1473', 'starttime': '2020-09-01 00:00:07.7440', 'stoptime': '2020-09-01 00:24:41.1800', 'start station id': '3946', 'start station name': 'St Nicholas Ave & W 137 St', 'start station latitude': '40.818477', 'start station longitude': '-73.947568', 'end station id': '4002', 'end station name': 'W 144 St & Adam Clayton Powell Blvd', 'end station latitude': '40.820877', 'end station longitude': '-73.939249', 'bikeid': '35860', 'usertype': 'Customer', 'birth year': '1990', 'gender': '2'}\n",
      "{'tripduration': '1193', 'starttime': '2020-09-01 00:00:12.2020', 'stoptime': '2020-09-01 00:20:05.5470', 'start station id': '3081', 'start station name': 'Graham Ave & Grand St', 'start station latitude': '40.711863', 'start station longitude': '-73.944024', 'end station id': '3048', 'end station name': 'Putnam Ave & Nostrand Ave', 'end station latitude': '40.68402', 'end station longitude': '-73.94977', 'bikeid': '26396', 'usertype': 'Customer', 'birth year': '1969', 'gender': '0'}\n"
     ]
    }
   ],
   "source": [
    "# Reading data from CSVs\n",
    "# csv_parsing.py\n",
    "\n",
    "# import the `csv` library\n",
    "import csv\n",
    "# open the `202009CitibikeTripdataExample.csv` file in read (\"r\") mode\n",
    "# this file should be in the same folder as our Python script or notebook\n",
    "source_file = open(\"202009CitibikeTripdataExample.csv\",\"r\")\n",
    "# pass our `source_file` as an ingredient to the `csv` library's\n",
    "# DictReader \"recipe\".\n",
    "# store the result in a variable called `citibike_reader`\n",
    "citibike_reader = csv.DictReader(source_file)\n",
    "# the DictReader method has added some useful information to our data,\n",
    "# like a `fieldnames` property that lets us access all the values\n",
    "# in the first or \"header\" row\n",
    "print(citibike_reader.fieldnames)\n",
    "# let's just print out the first 5 rows\n",
    "for i in range(0,5):\n",
    " print (next(citibike_reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Justice', 'Term Start/End', 'Party', 'State', 'Pres Appt', 'Other Offices Held', 'Relevant Prosecutorial Background']\n",
      "{'': '40', 'Justice': 'William Strong', 'Term Start/End': '1870-1880', 'Party': 'D/R', 'State': 'PA', 'Pres Appt': 'Grant', 'Other Offices Held': 'US House, Supr Court of PA, elect comm for elec of 1876', 'Relevant Prosecutorial Background': 'lawyer'}\n"
     ]
    }
   ],
   "source": [
    "#Reading data from TSV and TXT files\n",
    "# Example 4-2. tsv_parsing.py\n",
    "\n",
    "# import the `csv` library\n",
    "import csv\n",
    "# open the `ShugermanProsecutorPoliticians-SupremeCourtJustices.tsv` file\n",
    "# in read (\"r\") mode.\n",
    "# this file should be in the same folder as our Python script or notebook\n",
    "tsv_source_file = open(\"ShugermanProsecutorPoliticians-SupremeCourtJustices.tsv\",\"r\")\n",
    "# pass our `tsv_source_file` as an ingredient to the csv library's\n",
    "# DictReader \"recipe.\"\n",
    "# store the result in a variable called `politicians_reader`\n",
    "politicians_reader = csv.DictReader(tsv_source_file, delimiter='\\t')\n",
    "# the DictReader method has added some useful information to our data,\n",
    "# like a `fieldnames` property that lets us access all the values\n",
    "# in the first or \"header\" row\n",
    "print(politicians_reader.fieldnames)\n",
    "# we'll use the `next()` function to print just the first row of data\n",
    "print (next(politicians_reader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Justice', 'Term Start/End', 'Party', 'State', 'Pres Appt', 'Other Offices Held', 'Relevant Prosecutorial Background']\n",
      "{'': '40', 'Justice': 'William Strong', 'Term Start/End': '1870-1880', 'Party': 'D/R', 'State': 'PA', 'Pres Appt': 'Grant', 'Other Offices Held': 'US House, Supr Court of PA, elect comm for elec of 1876', 'Relevant Prosecutorial Background': 'lawyer'}\n"
     ]
    }
   ],
   "source": [
    "# Example 4-3. txt_parsing.py\n",
    "# the original .tsv file was renamed with a file extension of .txt\n",
    "# import the `csv` library\n",
    "import csv\n",
    "# open the `ShugermanProsecutorPoliticians-SupremeCourtJustices.txt` file\n",
    "# in read (\"r\") mode.\n",
    "# this file should be in the same folder as our Python script or notebook\n",
    "txt_source_file = open(\"ShugermanProsecutorPoliticians-SupremeCourtJustices.txt\",\"r\")\n",
    "# pass our txt_source_file as an ingredient to the csv library's DictReader\n",
    "# \"recipe\" and store the result in a variable called `politicians_reader`\n",
    "# add the \"delimiter\" parameter and specify the tab character, \"\\t\"\n",
    "politicians_reader = csv.DictReader(txt_source_file, delimiter='\\t')\n",
    "# the DictReader function has added useful information to our data,\n",
    "# like a label that shows us all the values in the first or \"header\" row\n",
    "print(politicians_reader.fieldnames)\n",
    "# we'll use the `next()` function to print just the first row of data\n",
    "print (next(politicians_reader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FRED Graph']\n",
      "FRED Graph\n",
      "<Cell 'FRED Graph'.A1> FRED Graph Observations\n",
      "<Cell 'FRED Graph'.B1> None\n",
      "<Cell 'FRED Graph'.A2> Federal Reserve Economic Data\n",
      "<Cell 'FRED Graph'.B2> None\n",
      "<Cell 'FRED Graph'.A3> Link: https://fred.stlouisfed.org\n",
      "<Cell 'FRED Graph'.B3> None\n",
      "<Cell 'FRED Graph'.A4> Help: https://fredhelp.stlouisfed.org\n",
      "<Cell 'FRED Graph'.B4> None\n",
      "<Cell 'FRED Graph'.A5> Economic Research Division\n",
      "<Cell 'FRED Graph'.B5> None\n",
      "<Cell 'FRED Graph'.A6> Federal Reserve Bank of St. Louis\n",
      "<Cell 'FRED Graph'.B6> None\n",
      "<Cell 'FRED Graph'.A7> None\n",
      "<Cell 'FRED Graph'.B7> None\n",
      "<Cell 'FRED Graph'.A8> U6RATE\n",
      "<Cell 'FRED Graph'.B8> Total Unemployed, Plus All Persons Marginally Attached to the Labor Force, Plus Total Employed Part Time for Economic Reasons, as a Percent of the Civilian Labor Force Plus All Persons Marginally Attached to the Labor Force (U-6), Percent, Monthly, Seasonally Adjusted\n",
      "<Cell 'FRED Graph'.A9> None\n",
      "<Cell 'FRED Graph'.B9> None\n",
      "<Cell 'FRED Graph'.A10> Frequency: Monthly\n",
      "<Cell 'FRED Graph'.B10> None\n",
      "<Cell 'FRED Graph'.A11> observation_date\n",
      "<Cell 'FRED Graph'.B11> U6RATE\n",
      "<Cell 'FRED Graph'.A12> 1994-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B12> 11.7\n",
      "<Cell 'FRED Graph'.A13> 1994-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B13> 11.4\n",
      "<Cell 'FRED Graph'.A14> 1994-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B14> 11.5\n",
      "<Cell 'FRED Graph'.A15> 1994-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B15> 11.3\n",
      "<Cell 'FRED Graph'.A16> 1994-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B16> 10.9\n",
      "<Cell 'FRED Graph'.A17> 1994-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B17> 11\n",
      "<Cell 'FRED Graph'.A18> 1994-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B18> 10.8\n",
      "<Cell 'FRED Graph'.A19> 1994-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B19> 10.6\n",
      "<Cell 'FRED Graph'.A20> 1994-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B20> 10.4\n",
      "<Cell 'FRED Graph'.A21> 1994-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B21> 10.4\n",
      "<Cell 'FRED Graph'.A22> 1994-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B22> 10.1\n",
      "<Cell 'FRED Graph'.A23> 1994-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B23> 10.1\n",
      "<Cell 'FRED Graph'.A24> 1995-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B24> 10.1\n",
      "<Cell 'FRED Graph'.A25> 1995-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B25> 9.9\n",
      "<Cell 'FRED Graph'.A26> 1995-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B26> 9.9\n",
      "<Cell 'FRED Graph'.A27> 1995-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B27> 10.1\n",
      "<Cell 'FRED Graph'.A28> 1995-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B28> 10.1\n",
      "<Cell 'FRED Graph'.A29> 1995-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B29> 10.1\n",
      "<Cell 'FRED Graph'.A30> 1995-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B30> 10.1\n",
      "<Cell 'FRED Graph'.A31> 1995-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B31> 10.1\n",
      "<Cell 'FRED Graph'.A32> 1995-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B32> 10.2\n",
      "<Cell 'FRED Graph'.A33> 1995-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B33> 10\n",
      "<Cell 'FRED Graph'.A34> 1995-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B34> 10.1\n",
      "<Cell 'FRED Graph'.A35> 1995-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B35> 10\n",
      "<Cell 'FRED Graph'.A36> 1996-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B36> 9.8\n",
      "<Cell 'FRED Graph'.A37> 1996-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B37> 10\n",
      "<Cell 'FRED Graph'.A38> 1996-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B38> 9.9\n",
      "<Cell 'FRED Graph'.A39> 1996-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B39> 10\n",
      "<Cell 'FRED Graph'.A40> 1996-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B40> 9.8\n",
      "<Cell 'FRED Graph'.A41> 1996-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B41> 9.7\n",
      "<Cell 'FRED Graph'.A42> 1996-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B42> 9.7\n",
      "<Cell 'FRED Graph'.A43> 1996-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B43> 9.4\n",
      "<Cell 'FRED Graph'.A44> 1996-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B44> 9.5\n",
      "<Cell 'FRED Graph'.A45> 1996-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B45> 9.5\n",
      "<Cell 'FRED Graph'.A46> 1996-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B46> 9.4\n",
      "<Cell 'FRED Graph'.A47> 1996-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B47> 9.6\n",
      "<Cell 'FRED Graph'.A48> 1997-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B48> 9.4\n",
      "<Cell 'FRED Graph'.A49> 1997-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B49> 9.3\n",
      "<Cell 'FRED Graph'.A50> 1997-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B50> 9.1\n",
      "<Cell 'FRED Graph'.A51> 1997-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B51> 9.3\n",
      "<Cell 'FRED Graph'.A52> 1997-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B52> 8.9\n",
      "<Cell 'FRED Graph'.A53> 1997-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B53> 8.9\n",
      "<Cell 'FRED Graph'.A54> 1997-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B54> 8.7\n",
      "<Cell 'FRED Graph'.A55> 1997-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B55> 8.7\n",
      "<Cell 'FRED Graph'.A56> 1997-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B56> 8.7\n",
      "<Cell 'FRED Graph'.A57> 1997-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B57> 8.5\n",
      "<Cell 'FRED Graph'.A58> 1997-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B58> 8.4\n",
      "<Cell 'FRED Graph'.A59> 1997-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B59> 8.5\n",
      "<Cell 'FRED Graph'.A60> 1998-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B60> 8.4\n",
      "<Cell 'FRED Graph'.A61> 1998-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B61> 8.3\n",
      "<Cell 'FRED Graph'.A62> 1998-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B62> 8.4\n",
      "<Cell 'FRED Graph'.A63> 1998-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B63> 8\n",
      "<Cell 'FRED Graph'.A64> 1998-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B64> 8\n",
      "<Cell 'FRED Graph'.A65> 1998-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B65> 8.1\n",
      "<Cell 'FRED Graph'.A66> 1998-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B66> 8.2\n",
      "<Cell 'FRED Graph'.A67> 1998-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B67> 7.9\n",
      "<Cell 'FRED Graph'.A68> 1998-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B68> 8\n",
      "<Cell 'FRED Graph'.A69> 1998-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B69> 7.9\n",
      "<Cell 'FRED Graph'.A70> 1998-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B70> 7.7\n",
      "<Cell 'FRED Graph'.A71> 1998-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B71> 7.6\n",
      "<Cell 'FRED Graph'.A72> 1999-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B72> 7.6\n",
      "<Cell 'FRED Graph'.A73> 1999-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B73> 7.7\n",
      "<Cell 'FRED Graph'.A74> 1999-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B74> 7.5\n",
      "<Cell 'FRED Graph'.A75> 1999-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B75> 7.7\n",
      "<Cell 'FRED Graph'.A76> 1999-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B76> 7.4\n",
      "<Cell 'FRED Graph'.A77> 1999-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B77> 7.5\n",
      "<Cell 'FRED Graph'.A78> 1999-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B78> 7.5\n",
      "<Cell 'FRED Graph'.A79> 1999-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B79> 7.3\n",
      "<Cell 'FRED Graph'.A80> 1999-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B80> 7.4\n",
      "<Cell 'FRED Graph'.A81> 1999-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B81> 7.2\n",
      "<Cell 'FRED Graph'.A82> 1999-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B82> 7.2\n",
      "<Cell 'FRED Graph'.A83> 1999-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B83> 7.1\n",
      "<Cell 'FRED Graph'.A84> 2000-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B84> 7\n",
      "<Cell 'FRED Graph'.A85> 2000-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B85> 7.1\n",
      "<Cell 'FRED Graph'.A86> 2000-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B86> 7.1\n",
      "<Cell 'FRED Graph'.A87> 2000-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B87> 6.9\n",
      "<Cell 'FRED Graph'.A88> 2000-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B88> 7.1\n",
      "<Cell 'FRED Graph'.A89> 2000-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B89> 7\n",
      "<Cell 'FRED Graph'.A90> 2000-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B90> 7\n",
      "<Cell 'FRED Graph'.A91> 2000-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B91> 7.1\n",
      "<Cell 'FRED Graph'.A92> 2000-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B92> 7\n",
      "<Cell 'FRED Graph'.A93> 2000-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B93> 6.8\n",
      "<Cell 'FRED Graph'.A94> 2000-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B94> 7.1\n",
      "<Cell 'FRED Graph'.A95> 2000-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B95> 6.9\n",
      "<Cell 'FRED Graph'.A96> 2001-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B96> 7.3\n",
      "<Cell 'FRED Graph'.A97> 2001-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B97> 7.3\n",
      "<Cell 'FRED Graph'.A98> 2001-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B98> 7.3\n",
      "<Cell 'FRED Graph'.A99> 2001-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B99> 7.4\n",
      "<Cell 'FRED Graph'.A100> 2001-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B100> 7.5\n",
      "<Cell 'FRED Graph'.A101> 2001-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B101> 7.9\n",
      "<Cell 'FRED Graph'.A102> 2001-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B102> 7.9\n",
      "<Cell 'FRED Graph'.A103> 2001-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B103> 8.2\n",
      "<Cell 'FRED Graph'.A104> 2001-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B104> 8.7\n",
      "<Cell 'FRED Graph'.A105> 2001-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B105> 9.3\n",
      "<Cell 'FRED Graph'.A106> 2001-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B106> 9.4\n",
      "<Cell 'FRED Graph'.A107> 2001-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B107> 9.6\n",
      "<Cell 'FRED Graph'.A108> 2002-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B108> 9.4\n",
      "<Cell 'FRED Graph'.A109> 2002-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B109> 9.5\n",
      "<Cell 'FRED Graph'.A110> 2002-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B110> 9.4\n",
      "<Cell 'FRED Graph'.A111> 2002-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B111> 9.7\n",
      "<Cell 'FRED Graph'.A112> 2002-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B112> 9.6\n",
      "<Cell 'FRED Graph'.A113> 2002-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B113> 9.5\n",
      "<Cell 'FRED Graph'.A114> 2002-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B114> 9.6\n",
      "<Cell 'FRED Graph'.A115> 2002-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B115> 9.6\n",
      "<Cell 'FRED Graph'.A116> 2002-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B116> 9.6\n",
      "<Cell 'FRED Graph'.A117> 2002-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B117> 9.6\n",
      "<Cell 'FRED Graph'.A118> 2002-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B118> 9.8\n",
      "<Cell 'FRED Graph'.A119> 2002-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B119> 9.8\n",
      "<Cell 'FRED Graph'.A120> 2003-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B120> 9.9\n",
      "<Cell 'FRED Graph'.A121> 2003-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B121> 10.1\n",
      "<Cell 'FRED Graph'.A122> 2003-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B122> 10\n",
      "<Cell 'FRED Graph'.A123> 2003-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B123> 10.2\n",
      "<Cell 'FRED Graph'.A124> 2003-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B124> 10.1\n",
      "<Cell 'FRED Graph'.A125> 2003-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B125> 10.3\n",
      "<Cell 'FRED Graph'.A126> 2003-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B126> 10.3\n",
      "<Cell 'FRED Graph'.A127> 2003-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B127> 10.1\n",
      "<Cell 'FRED Graph'.A128> 2003-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B128> 10.4\n",
      "<Cell 'FRED Graph'.A129> 2003-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B129> 10.2\n",
      "<Cell 'FRED Graph'.A130> 2003-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B130> 10.1\n",
      "<Cell 'FRED Graph'.A131> 2003-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B131> 9.8\n",
      "<Cell 'FRED Graph'.A132> 2004-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B132> 9.8\n",
      "<Cell 'FRED Graph'.A133> 2004-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B133> 9.7\n",
      "<Cell 'FRED Graph'.A134> 2004-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B134> 10\n",
      "<Cell 'FRED Graph'.A135> 2004-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B135> 9.6\n",
      "<Cell 'FRED Graph'.A136> 2004-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B136> 9.7\n",
      "<Cell 'FRED Graph'.A137> 2004-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B137> 9.6\n",
      "<Cell 'FRED Graph'.A138> 2004-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B138> 9.5\n",
      "<Cell 'FRED Graph'.A139> 2004-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B139> 9.4\n",
      "<Cell 'FRED Graph'.A140> 2004-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B140> 9.4\n",
      "<Cell 'FRED Graph'.A141> 2004-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B141> 9.7\n",
      "<Cell 'FRED Graph'.A142> 2004-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B142> 9.4\n",
      "<Cell 'FRED Graph'.A143> 2004-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B143> 9.3\n",
      "<Cell 'FRED Graph'.A144> 2005-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B144> 9.2\n",
      "<Cell 'FRED Graph'.A145> 2005-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B145> 9.2\n",
      "<Cell 'FRED Graph'.A146> 2005-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B146> 9.1\n",
      "<Cell 'FRED Graph'.A147> 2005-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B147> 9\n",
      "<Cell 'FRED Graph'.A148> 2005-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B148> 8.9\n",
      "<Cell 'FRED Graph'.A149> 2005-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B149> 9\n",
      "<Cell 'FRED Graph'.A150> 2005-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B150> 8.8\n",
      "<Cell 'FRED Graph'.A151> 2005-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B151> 8.9\n",
      "<Cell 'FRED Graph'.A152> 2005-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B152> 9\n",
      "<Cell 'FRED Graph'.A153> 2005-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B153> 8.7\n",
      "<Cell 'FRED Graph'.A154> 2005-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B154> 8.7\n",
      "<Cell 'FRED Graph'.A155> 2005-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B155> 8.6\n",
      "<Cell 'FRED Graph'.A156> 2006-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B156> 8.4\n",
      "<Cell 'FRED Graph'.A157> 2006-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B157> 8.4\n",
      "<Cell 'FRED Graph'.A158> 2006-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B158> 8.2\n",
      "<Cell 'FRED Graph'.A159> 2006-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B159> 8.1\n",
      "<Cell 'FRED Graph'.A160> 2006-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B160> 8.2\n",
      "<Cell 'FRED Graph'.A161> 2006-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B161> 8.4\n",
      "<Cell 'FRED Graph'.A162> 2006-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B162> 8.5\n",
      "<Cell 'FRED Graph'.A163> 2006-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B163> 8.4\n",
      "<Cell 'FRED Graph'.A164> 2006-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B164> 8\n",
      "<Cell 'FRED Graph'.A165> 2006-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B165> 8.2\n",
      "<Cell 'FRED Graph'.A166> 2006-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B166> 8.1\n",
      "<Cell 'FRED Graph'.A167> 2006-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B167> 7.9\n",
      "<Cell 'FRED Graph'.A168> 2007-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B168> 8.3\n",
      "<Cell 'FRED Graph'.A169> 2007-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B169> 8.1\n",
      "<Cell 'FRED Graph'.A170> 2007-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B170> 8\n",
      "<Cell 'FRED Graph'.A171> 2007-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B171> 8.2\n",
      "<Cell 'FRED Graph'.A172> 2007-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B172> 8.2\n",
      "<Cell 'FRED Graph'.A173> 2007-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B173> 8.3\n",
      "<Cell 'FRED Graph'.A174> 2007-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B174> 8.4\n",
      "<Cell 'FRED Graph'.A175> 2007-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B175> 8.4\n",
      "<Cell 'FRED Graph'.A176> 2007-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B176> 8.4\n",
      "<Cell 'FRED Graph'.A177> 2007-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B177> 8.4\n",
      "<Cell 'FRED Graph'.A178> 2007-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B178> 8.5\n",
      "<Cell 'FRED Graph'.A179> 2007-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B179> 8.8\n",
      "<Cell 'FRED Graph'.A180> 2008-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B180> 9.1\n",
      "<Cell 'FRED Graph'.A181> 2008-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B181> 9\n",
      "<Cell 'FRED Graph'.A182> 2008-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B182> 9.1\n",
      "<Cell 'FRED Graph'.A183> 2008-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B183> 9.2\n",
      "<Cell 'FRED Graph'.A184> 2008-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B184> 9.7\n",
      "<Cell 'FRED Graph'.A185> 2008-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B185> 10\n",
      "<Cell 'FRED Graph'.A186> 2008-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B186> 10.5\n",
      "<Cell 'FRED Graph'.A187> 2008-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B187> 10.8\n",
      "<Cell 'FRED Graph'.A188> 2008-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B188> 11.1\n",
      "<Cell 'FRED Graph'.A189> 2008-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B189> 11.8\n",
      "<Cell 'FRED Graph'.A190> 2008-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B190> 12.7\n",
      "<Cell 'FRED Graph'.A191> 2008-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B191> 13.6\n",
      "<Cell 'FRED Graph'.A192> 2009-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B192> 14.1\n",
      "<Cell 'FRED Graph'.A193> 2009-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B193> 15.1\n",
      "<Cell 'FRED Graph'.A194> 2009-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B194> 15.8\n",
      "<Cell 'FRED Graph'.A195> 2009-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B195> 15.9\n",
      "<Cell 'FRED Graph'.A196> 2009-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B196> 16.5\n",
      "<Cell 'FRED Graph'.A197> 2009-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B197> 16.5\n",
      "<Cell 'FRED Graph'.A198> 2009-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B198> 16.4\n",
      "<Cell 'FRED Graph'.A199> 2009-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B199> 16.7\n",
      "<Cell 'FRED Graph'.A200> 2009-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B200> 16.7\n",
      "<Cell 'FRED Graph'.A201> 2009-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B201> 17.1\n",
      "<Cell 'FRED Graph'.A202> 2009-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B202> 17.1\n",
      "<Cell 'FRED Graph'.A203> 2009-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B203> 17.2\n",
      "<Cell 'FRED Graph'.A204> 2010-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B204> 16.6\n",
      "<Cell 'FRED Graph'.A205> 2010-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B205> 17\n",
      "<Cell 'FRED Graph'.A206> 2010-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B206> 17.1\n",
      "<Cell 'FRED Graph'.A207> 2010-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B207> 17.2\n",
      "<Cell 'FRED Graph'.A208> 2010-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B208> 16.7\n",
      "<Cell 'FRED Graph'.A209> 2010-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B209> 16.4\n",
      "<Cell 'FRED Graph'.A210> 2010-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B210> 16.4\n",
      "<Cell 'FRED Graph'.A211> 2010-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B211> 16.5\n",
      "<Cell 'FRED Graph'.A212> 2010-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B212> 16.9\n",
      "<Cell 'FRED Graph'.A213> 2010-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B213> 16.6\n",
      "<Cell 'FRED Graph'.A214> 2010-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B214> 16.9\n",
      "<Cell 'FRED Graph'.A215> 2010-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B215> 16.6\n",
      "<Cell 'FRED Graph'.A216> 2011-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B216> 16.1\n",
      "<Cell 'FRED Graph'.A217> 2011-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B217> 16\n",
      "<Cell 'FRED Graph'.A218> 2011-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B218> 16\n",
      "<Cell 'FRED Graph'.A219> 2011-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B219> 16.1\n",
      "<Cell 'FRED Graph'.A220> 2011-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B220> 15.9\n",
      "<Cell 'FRED Graph'.A221> 2011-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B221> 16.1\n",
      "<Cell 'FRED Graph'.A222> 2011-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B222> 15.9\n",
      "<Cell 'FRED Graph'.A223> 2011-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B223> 16.1\n",
      "<Cell 'FRED Graph'.A224> 2011-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B224> 16.4\n",
      "<Cell 'FRED Graph'.A225> 2011-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B225> 15.8\n",
      "<Cell 'FRED Graph'.A226> 2011-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B226> 15.6\n",
      "<Cell 'FRED Graph'.A227> 2011-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B227> 15.2\n",
      "<Cell 'FRED Graph'.A228> 2012-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B228> 15.1\n",
      "<Cell 'FRED Graph'.A229> 2012-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B229> 15\n",
      "<Cell 'FRED Graph'.A230> 2012-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B230> 14.6\n",
      "<Cell 'FRED Graph'.A231> 2012-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B231> 14.7\n",
      "<Cell 'FRED Graph'.A232> 2012-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B232> 14.8\n",
      "<Cell 'FRED Graph'.A233> 2012-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B233> 14.7\n",
      "<Cell 'FRED Graph'.A234> 2012-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B234> 14.7\n",
      "<Cell 'FRED Graph'.A235> 2012-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B235> 14.6\n",
      "<Cell 'FRED Graph'.A236> 2012-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B236> 14.8\n",
      "<Cell 'FRED Graph'.A237> 2012-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B237> 14.4\n",
      "<Cell 'FRED Graph'.A238> 2012-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B238> 14.4\n",
      "<Cell 'FRED Graph'.A239> 2012-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B239> 14.4\n",
      "<Cell 'FRED Graph'.A240> 2013-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B240> 14.5\n",
      "<Cell 'FRED Graph'.A241> 2013-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B241> 14.3\n",
      "<Cell 'FRED Graph'.A242> 2013-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B242> 13.9\n",
      "<Cell 'FRED Graph'.A243> 2013-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B243> 14\n",
      "<Cell 'FRED Graph'.A244> 2013-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B244> 13.9\n",
      "<Cell 'FRED Graph'.A245> 2013-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B245> 14.2\n",
      "<Cell 'FRED Graph'.A246> 2013-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B246> 13.8\n",
      "<Cell 'FRED Graph'.A247> 2013-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B247> 13.6\n",
      "<Cell 'FRED Graph'.A248> 2013-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B248> 13.5\n",
      "<Cell 'FRED Graph'.A249> 2013-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B249> 13.6\n",
      "<Cell 'FRED Graph'.A250> 2013-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B250> 13.1\n",
      "<Cell 'FRED Graph'.A251> 2013-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B251> 13.1\n",
      "<Cell 'FRED Graph'.A252> 2014-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B252> 12.6\n",
      "<Cell 'FRED Graph'.A253> 2014-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B253> 12.6\n",
      "<Cell 'FRED Graph'.A254> 2014-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B254> 12.7\n",
      "<Cell 'FRED Graph'.A255> 2014-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B255> 12.3\n",
      "<Cell 'FRED Graph'.A256> 2014-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B256> 12.3\n",
      "<Cell 'FRED Graph'.A257> 2014-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B257> 12\n",
      "<Cell 'FRED Graph'.A258> 2014-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B258> 12.1\n",
      "<Cell 'FRED Graph'.A259> 2014-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B259> 12\n",
      "<Cell 'FRED Graph'.A260> 2014-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B260> 11.7\n",
      "<Cell 'FRED Graph'.A261> 2014-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B261> 11.5\n",
      "<Cell 'FRED Graph'.A262> 2014-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B262> 11.4\n",
      "<Cell 'FRED Graph'.A263> 2014-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B263> 11.2\n",
      "<Cell 'FRED Graph'.A264> 2015-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B264> 11.2\n",
      "<Cell 'FRED Graph'.A265> 2015-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B265> 10.9\n",
      "<Cell 'FRED Graph'.A266> 2015-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B266> 10.9\n",
      "<Cell 'FRED Graph'.A267> 2015-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B267> 10.9\n",
      "<Cell 'FRED Graph'.A268> 2015-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B268> 10.9\n",
      "<Cell 'FRED Graph'.A269> 2015-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B269> 10.4\n",
      "<Cell 'FRED Graph'.A270> 2015-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B270> 10.3\n",
      "<Cell 'FRED Graph'.A271> 2015-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B271> 10.2\n",
      "<Cell 'FRED Graph'.A272> 2015-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B272> 10\n",
      "<Cell 'FRED Graph'.A273> 2015-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B273> 9.8\n",
      "<Cell 'FRED Graph'.A274> 2015-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B274> 10\n",
      "<Cell 'FRED Graph'.A275> 2015-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B275> 9.9\n",
      "<Cell 'FRED Graph'.A276> 2016-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B276> 9.7\n",
      "<Cell 'FRED Graph'.A277> 2016-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B277> 9.6\n",
      "<Cell 'FRED Graph'.A278> 2016-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B278> 9.8\n",
      "<Cell 'FRED Graph'.A279> 2016-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B279> 9.9\n",
      "<Cell 'FRED Graph'.A280> 2016-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B280> 9.9\n",
      "<Cell 'FRED Graph'.A281> 2016-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B281> 9.5\n",
      "<Cell 'FRED Graph'.A282> 2016-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B282> 9.6\n",
      "<Cell 'FRED Graph'.A283> 2016-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B283> 9.6\n",
      "<Cell 'FRED Graph'.A284> 2016-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B284> 9.7\n",
      "<Cell 'FRED Graph'.A285> 2016-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B285> 9.6\n",
      "<Cell 'FRED Graph'.A286> 2016-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B286> 9.4\n",
      "<Cell 'FRED Graph'.A287> 2016-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B287> 9.2\n",
      "<Cell 'FRED Graph'.A288> 2017-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B288> 9.2\n",
      "<Cell 'FRED Graph'.A289> 2017-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B289> 9\n",
      "<Cell 'FRED Graph'.A290> 2017-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B290> 8.8\n",
      "<Cell 'FRED Graph'.A291> 2017-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B291> 8.6\n",
      "<Cell 'FRED Graph'.A292> 2017-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B292> 8.5\n",
      "<Cell 'FRED Graph'.A293> 2017-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B293> 8.5\n",
      "<Cell 'FRED Graph'.A294> 2017-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B294> 8.5\n",
      "<Cell 'FRED Graph'.A295> 2017-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B295> 8.6\n",
      "<Cell 'FRED Graph'.A296> 2017-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B296> 8.3\n",
      "<Cell 'FRED Graph'.A297> 2017-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B297> 8.1\n",
      "<Cell 'FRED Graph'.A298> 2017-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B298> 8\n",
      "<Cell 'FRED Graph'.A299> 2017-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B299> 8.1\n",
      "<Cell 'FRED Graph'.A300> 2018-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B300> 8\n",
      "<Cell 'FRED Graph'.A301> 2018-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B301> 8.1\n",
      "<Cell 'FRED Graph'.A302> 2018-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B302> 8\n",
      "<Cell 'FRED Graph'.A303> 2018-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B303> 7.9\n",
      "<Cell 'FRED Graph'.A304> 2018-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B304> 7.8\n",
      "<Cell 'FRED Graph'.A305> 2018-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B305> 7.8\n",
      "<Cell 'FRED Graph'.A306> 2018-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B306> 7.5\n",
      "<Cell 'FRED Graph'.A307> 2018-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B307> 7.4\n",
      "<Cell 'FRED Graph'.A308> 2018-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B308> 7.5\n",
      "<Cell 'FRED Graph'.A309> 2018-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B309> 7.5\n",
      "<Cell 'FRED Graph'.A310> 2018-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B310> 7.6\n",
      "<Cell 'FRED Graph'.A311> 2018-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B311> 7.6\n",
      "<Cell 'FRED Graph'.A312> 2019-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B312> 8\n",
      "<Cell 'FRED Graph'.A313> 2019-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B313> 7.2\n",
      "<Cell 'FRED Graph'.A314> 2019-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B314> 7.4\n",
      "<Cell 'FRED Graph'.A315> 2019-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B315> 7.4\n",
      "<Cell 'FRED Graph'.A316> 2019-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B316> 7.1\n",
      "<Cell 'FRED Graph'.A317> 2019-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B317> 7.2\n",
      "<Cell 'FRED Graph'.A318> 2019-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B318> 6.9\n",
      "<Cell 'FRED Graph'.A319> 2019-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B319> 7.2\n",
      "<Cell 'FRED Graph'.A320> 2019-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B320> 6.9\n",
      "<Cell 'FRED Graph'.A321> 2019-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B321> 6.9\n",
      "<Cell 'FRED Graph'.A322> 2019-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B322> 6.8\n",
      "<Cell 'FRED Graph'.A323> 2019-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B323> 6.8\n",
      "<Cell 'FRED Graph'.A324> 2020-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B324> 6.9\n",
      "<Cell 'FRED Graph'.A325> 2020-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B325> 7\n",
      "<Cell 'FRED Graph'.A326> 2020-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B326> 8.8\n",
      "<Cell 'FRED Graph'.A327> 2020-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B327> 22.9\n",
      "<Cell 'FRED Graph'.A328> 2020-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B328> 21.1\n",
      "<Cell 'FRED Graph'.A329> 2020-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B329> 18\n",
      "<Cell 'FRED Graph'.A330> 2020-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B330> 16.5\n",
      "<Cell 'FRED Graph'.A331> 2020-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B331> 14.2\n",
      "<Cell 'FRED Graph'.A332> 2020-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B332> 12.8\n",
      "<Cell 'FRED Graph'.A333> 2020-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B333> 12\n",
      "<Cell 'FRED Graph'.A334> 2020-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B334> 11.9\n",
      "<Cell 'FRED Graph'.A335> 2020-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B335> 11.7\n",
      "<Cell 'FRED Graph'.A336> 2021-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B336> 11.2\n",
      "<Cell 'FRED Graph'.A337> 2021-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B337> 11.1\n",
      "<Cell 'FRED Graph'.A338> 2021-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B338> 10.8\n",
      "<Cell 'FRED Graph'.A339> 2021-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B339> 10.4\n",
      "<Cell 'FRED Graph'.A340> 2021-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B340> 10.1\n",
      "<Cell 'FRED Graph'.A341> 2021-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B341> 9.8\n",
      "<Cell 'FRED Graph'.A342> 2021-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B342> 9.2\n",
      "<Cell 'FRED Graph'.A343> 2021-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B343> 8.8\n",
      "<Cell 'FRED Graph'.A344> 2021-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B344> 8.4\n",
      "<Cell 'FRED Graph'.A345> 2021-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B345> 8.1\n",
      "<Cell 'FRED Graph'.A346> 2021-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B346> 7.7\n",
      "<Cell 'FRED Graph'.A347> 2021-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B347> 7.3\n",
      "<Cell 'FRED Graph'.A348> 2022-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B348> 7.2\n",
      "<Cell 'FRED Graph'.A349> 2022-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B349> 7.2\n",
      "<Cell 'FRED Graph'.A350> 2022-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B350> 7\n",
      "<Cell 'FRED Graph'.A351> 2022-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B351> 7.1\n",
      "<Cell 'FRED Graph'.A352> 2022-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B352> 7.1\n",
      "<Cell 'FRED Graph'.A353> 2022-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B353> 6.7\n",
      "<Cell 'FRED Graph'.A354> 2022-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B354> 6.8\n",
      "<Cell 'FRED Graph'.A355> 2022-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B355> 7\n",
      "<Cell 'FRED Graph'.A356> 2022-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B356> 6.7\n",
      "<Cell 'FRED Graph'.A357> 2022-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B357> 6.7\n",
      "<Cell 'FRED Graph'.A358> 2022-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B358> 6.7\n",
      "<Cell 'FRED Graph'.A359> 2022-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B359> 6.5\n",
      "<Cell 'FRED Graph'.A360> 2023-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B360> 6.7\n",
      "<Cell 'FRED Graph'.A361> 2023-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B361> 6.8\n",
      "<Cell 'FRED Graph'.A362> 2023-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B362> 6.7\n",
      "<Cell 'FRED Graph'.A363> 2023-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B363> 6.6\n",
      "<Cell 'FRED Graph'.A364> 2023-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B364> 6.8\n",
      "<Cell 'FRED Graph'.A365> 2023-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B365> 6.9\n",
      "<Cell 'FRED Graph'.A366> 2023-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B366> 6.7\n",
      "<Cell 'FRED Graph'.A367> 2023-08-01 00:00:00\n",
      "<Cell 'FRED Graph'.B367> 7.1\n",
      "<Cell 'FRED Graph'.A368> 2023-09-01 00:00:00\n",
      "<Cell 'FRED Graph'.B368> 7\n",
      "<Cell 'FRED Graph'.A369> 2023-10-01 00:00:00\n",
      "<Cell 'FRED Graph'.B369> 7.2\n",
      "<Cell 'FRED Graph'.A370> 2023-11-01 00:00:00\n",
      "<Cell 'FRED Graph'.B370> 7\n",
      "<Cell 'FRED Graph'.A371> 2023-12-01 00:00:00\n",
      "<Cell 'FRED Graph'.B371> 7.1\n",
      "<Cell 'FRED Graph'.A372> 2024-01-01 00:00:00\n",
      "<Cell 'FRED Graph'.B372> 7.2\n",
      "<Cell 'FRED Graph'.A373> 2024-02-01 00:00:00\n",
      "<Cell 'FRED Graph'.B373> 7.3\n",
      "<Cell 'FRED Graph'.A374> 2024-03-01 00:00:00\n",
      "<Cell 'FRED Graph'.B374> 7.3\n",
      "<Cell 'FRED Graph'.A375> 2024-04-01 00:00:00\n",
      "<Cell 'FRED Graph'.B375> 7.4\n",
      "<Cell 'FRED Graph'.A376> 2024-05-01 00:00:00\n",
      "<Cell 'FRED Graph'.B376> 7.4\n",
      "<Cell 'FRED Graph'.A377> 2024-06-01 00:00:00\n",
      "<Cell 'FRED Graph'.B377> 7.4\n",
      "<Cell 'FRED Graph'.A378> 2024-07-01 00:00:00\n",
      "<Cell 'FRED Graph'.B378> 7.8\n"
     ]
    }
   ],
   "source": [
    "# Reading Data from XLSX, ODS and all the rest\n",
    "# Example 4-4. xlsx_parsing.py\n",
    "\n",
    "# the source data can be composed and downloaded from:\n",
    "# https://fred.stlouisfed.org/series/U6RATE\n",
    "# specify the \"chapter\" you want to import from the \"openpyxl\" library\n",
    "# in this case, \"load_workbook\"\n",
    "from openpyxl import load_workbook\n",
    "# import the `csv` library, to create our output file\n",
    "import csv\n",
    "# pass our filename as an ingredient to the `openpyxl` library's\n",
    "# `load_workbook()` \"recipe\"\n",
    "# store the result in a variable called `source_workbook`\n",
    "source_workbook = load_workbook(filename = 'fredgraph.xlsx')\n",
    "# an .xlsx workbook can have multiple sheets\n",
    "# print their names here for reference\n",
    "print(source_workbook.sheetnames)   # --- 1\n",
    "# loop through the worksheets in `source_workbook`\n",
    "for sheet_num, sheet_name in enumerate(source_workbook.sheetnames):  # --- 2\n",
    "    # create a variable that points to the current worksheet by\n",
    "    # passing the current value of `sheet_name` to `source_workbook`\n",
    "    current_sheet = source_workbook[sheet_name]\n",
    "    # print `sheet_name`, just to see what it is\n",
    "    print(sheet_name)\n",
    "    # create an output file called \"xlsx_\"+sheet_name\n",
    "    output_file = open(\"xlsx_\"+sheet_name+\".csv\",\"w\")   # --- 3\n",
    "    # use this csv library's \"writer\" recipe to easily write rows of data\n",
    "    # to `output_file`, instead of reading data *from* it\n",
    "    output_writer = csv.writer(output_file)\n",
    "    # loop through every row in our sheet\n",
    "    for row in current_sheet.iter_rows():   # --- 4\n",
    "        # we'll create an empty list where we'll put the actual\n",
    "        # values of the cells in each row\n",
    "        row_cells = []    # --- 5\n",
    "    # for every cell (or column) in each row....\n",
    "        for cell in row:\n",
    "            # let's print what's in here, just to see how the code sees it\n",
    "            print(cell, cell.value)\n",
    "            # add the values to the end of our list with the `append()` method\n",
    "            row_cells.append(cell.value)\n",
    "        # write our newly (re)constructed data row to the output file\n",
    "        output_writer.writerow(row_cells)   # --- 6\n",
    "    # officially close the `.csv` file we just wrote all that data to\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Like the csv library’s DictReader() function, openpyxl’s load_workbook() func‐\n",
    "tion adds properties to our source data, in this case, one that shows us the names\n",
    "of all the data sheets in our workbook.<br><br>\n",
    "2. Even though our example workbook only includes one worksheet, we might have\n",
    "more in the future. We’ll use the enumerate() function so we can access both an\n",
    "iterator and the sheet name. This will help us create one .csv file per worksheet.<br><br>\n",
    "3. Each sheet in our source_workbook will need its own, uniquely named\n",
    "output .csv file. To generate these, we’ll “open” a new file with the name\n",
    "\"xlsx_\"+sheet_name+\".csv\" and make it writable by passing w as the “mode”\n",
    "argument (up until now, we’ve used the r mode to read data from .csvs).<br><br>\n",
    "4. The function iter_rows() is specific to the openpyxl library. Here, it converts the\n",
    "rows of source_workbook into a list that can be iterated, or looped, over.<br><br>\n",
    "5. The openpyxl library treats each data cell as a Python tuple data type. If we try\n",
    "to just print the rows of current_sheet directly, we’ll get sort of unhelpful cell\n",
    "locations, rather than the data values they contain. To address this, we’ll make\n",
    "another loop inside this one to go through every cell in every row one at a time\n",
    "and add the actual data values to row_cells.<br><br>\n",
    "6. Notice that this code is left-aligned with the for cell in row code in the\n",
    "example. This means that it is outside that loop and so will only be run after all\n",
    "the cells in a given row have been appended to our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4-5. ods_parsing.py\n",
    "# using the \"pyexcel_ods\" library. First, you'll need to pip install the library:\n",
    "# https://pypi.org/project/pyexcel-ods/\n",
    "# specify the \"chapter\" of the \"pyexcel_ods\" library you want to import,\n",
    "# in this case, `get_data`\n",
    "from pyexcel_ods import get_data\n",
    "# import the `csv` library, to create our output file\n",
    "import csv\n",
    "# pass our filename as an ingredient to the `pyexcel_ods` library's\n",
    "# `get_data()` \"recipe\"\n",
    "# store the result in a variable called `source_workbook`\n",
    "source_workbook = get_data(\"fredgraph.ods\")\n",
    "# an `.ods` workbook can have multiple sheets\n",
    "for sheet_name, sheet_data in source_workbook.items():  # ---1\n",
    "    # print `sheet_name`, just to see what it is\n",
    "    print(sheet_name)\n",
    "    # create \"ods_\"+sheet_name+\".csv\" as an output file for the current sheet\n",
    "    output_file = open(\"ods_\"+sheet_name+\".csv\",\"w\")\n",
    "    # use this csv library's \"writer\" recipe to easily write rows of data\n",
    "    # to `output_file`, instead of reading data *from* it\n",
    "    output_writer = csv.writer(output_file)\n",
    "    # now, we need to loop through every row in our sheet\n",
    "    for row in sheet_data:  # ---2\n",
    "        # use the `writerow` recipe to write each `row`\n",
    "        # directly to our output file\n",
    "        output_writer.writerow(row)   # ---3\n",
    "    # officially close the `.csv` file we just wrote all that data to\n",
    "    output_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The pyexcel_ods library converts our source data into Python’s OrderedDict data\n",
    "type. The associated items() method then lets us access each sheet’s name and\n",
    "data as a key/value pair that we can loop through. In this case, sheet_name is the\n",
    "“key” and the entire worksheet’s data is the “value.” <br><br>\n",
    "2. Here, sheet_data is already a list, so we can just loop through that list with a\n",
    "basic for loop.<br><br>\n",
    "3. This library converts each row in a worksheet to a list, which is why we can pass\n",
    "these directly to the writerow() method.<br><br>\n",
    "In the case of the pyexcel_ods library, the contents of our output .csv file much more\n",
    "closely resembles what we see visually when we open the original fredgraph.xls via a\n",
    "spreadsheet program like Google Sheets—the observation_date field, for example, is\n",
    "in a simple YYYY-MM-DD format. Moreover, the library creator(s) decided to treat\n",
    "the values in each row as a list, allowing us to write each record directly to our outputfile without creating any additional loops or lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRED Graph\n"
     ]
    }
   ],
   "source": [
    "# Example 4-6. xls_parsing.py\n",
    "\n",
    "# a simple example of reading data from a .xls file with Python using the \"xrld\" library. First, pip install the xlrd library:\n",
    "# https://pypi.org/project/xlrd/2.0.1/\n",
    "\n",
    "\n",
    "# import the \"xlrd\" library\n",
    "import xlrd\n",
    "# import the `csv` library, to create our output file\n",
    "import csv\n",
    "# pass our filename as an ingredient to the `xlrd` library's\n",
    "# `open_workbook()` \"recipe\"\n",
    "# store the result in a variable called `source_workbook`\n",
    "source_workbook = xlrd.open_workbook(\"fredgraph.xls\")\n",
    "# an `.xls` workbook can have multiple sheets\n",
    "for sheet_name in source_workbook.sheet_names():\n",
    "    # create a variable that points to the current worksheet by\n",
    "    # passing the current value of `sheet_name` to the `sheet_by_name` recipe\n",
    "    current_sheet = source_workbook.sheet_by_name(sheet_name)\n",
    "    # print `sheet_name\n",
    "    print(sheet_name)\n",
    "\n",
    "    # create \"xls_\"+sheet_name+\".csv\" as an output file for the current sheet\n",
    "    output_file = open(\"xls_\"+sheet_name+\".csv\",\"w\")\n",
    "    # use the `csv` library's \"writer\" recipe to easily write rows of data\n",
    "    # to `output_file`, instead of reading data *from* it\n",
    "    output_writer = csv.writer(output_file)\n",
    "    # now, we need to loop through every row in our sheet\n",
    "    for row_num, row in enumerate(current_sheet.get_rows()):\n",
    "        # each row is already a list, but we need to use the `row_value()`\n",
    "        # method to access them\n",
    "        # then we can use the `writerow` recipe to write them\n",
    "        # directly to our output file\n",
    "        output_writer.writerow(current_sheet.row_values(row_num))\n",
    "    # officially close the `.csv` file we just wrote all that data to\n",
    "    output_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Notice that this structure is similar to the one we use when working with the csv\n",
    "library.<br><br>\n",
    "2. The function get_rows() is specific to the xlrd library; it converts the rows of our\n",
    "current worksheet into a list that can be looped over.<br><br>\n",
    "3. There will be some funkiness within the “dates” written to our output file. We’ll\n",
    "look at how to fix up the dates in “Decrypting Excel Dates” <br><br>\n",
    "One thing we’ll see in this output file is some serious weirdness in the values recorded in the observation_date field, reflecting the fact that, as the xlrd library’s creators put it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed width Data\n",
    "each data column in a fixed-width table contains a specific, predefined number of characters and always that number of characters. This means that the meaningful data in fixed-width files are often padded with extra characters, such as spaces or zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4-7. fixed_width_parsing.py\n",
    "# an example of reading data from a fixed-width file with Python.\n",
    "# the source file for this example comes from NOAA and can be accessed here:\n",
    "# https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\n",
    "# the metadata for the file can be found here:\n",
    "# https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt\n",
    "\n",
    "\n",
    "# import the `csv` library, to create our output file\n",
    "import csv\n",
    "filename = \"ghcnd-stations\"\n",
    "# reading from a basic text file doesn't require any special libraries\n",
    "# so we'll just open the file in read format (\"r\") as usual\n",
    "source_file = open(filename+\".txt\", \"r\")\n",
    "# the built-in \"readlines()\" method does just what you'd think:\n",
    "# it reads in a text file and converts it to a list of lines\n",
    "stations_list = source_file.readlines()\n",
    "# create an output file for our transformed data\n",
    "output_file = open(filename+\".csv\",\"w\")\n",
    "# use the `csv` library's \"writer\" recipe to easily write rows of data\n",
    "# to `output_file`, instead of reading data *from* it\n",
    "output_writer = csv.writer(output_file)\n",
    "# create the header list\n",
    "headers = [\"ID\",\"LATITUDE\",\"LONGITUDE\",\"ELEVATION\",\"STATE\",\"NAME\",\"GSN_FLAG\",\n",
    " \"HCNCRN_FLAG\",\"WMO_ID\"] # ---1\n",
    "# write our headers to the output file\n",
    "output_writer.writerow(headers)\n",
    "# loop through each line of our file (multiple \"sheets\" are not possible)\n",
    "for line in stations_list:\n",
    "    # makes up a given \"column\" of data\n",
    "    new_row = []\n",
    "    # ID: positions 1-11\n",
    "    new_row.append(line[0:11])\n",
    "    # LATITUDE: positions 13-20\n",
    "    new_row.append(line[12:20])\n",
    "    # LONGITUDE: positions 22-30\n",
    "    new_row.append(line[21:30])\n",
    "    # ELEVATION: positions 32-37\n",
    "    new_row.append(line[31:37])\n",
    "    # STATE: positions 39-40\n",
    "    new_row.append(line[38:40])\n",
    "    # NAME: positions 42-71\n",
    "    new_row.append(line[41:71])\n",
    "    # GSN_FLAG: positions 73-75\n",
    "    new_row.append(line[72:75])\n",
    "    # HCNCRN_FLAG: positions 77-79\n",
    "    new_row.append(line[76:79])\n",
    "    # WMO_ID: positions 81-85\n",
    "    new_row.append(line[80:85])\n",
    "    # now all that's left is to use the\n",
    "    # `writerow` function to write new_row to our output file\n",
    "    output_writer.writerow(new_row)\n",
    "# officially close the `.csv` file we just wrote all that data to\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Since we don’t have anything within the file that we can draw on for column\n",
    "headers, we have to “hard code” them based on the information in the readme.txt\n",
    "file. Note that I’ve eliminated special characters and used underscores in place of\n",
    "spaces to minimize hassles when cleaning and analyzing this data later on.<br><br>\n",
    "2. Python actually views lines of text as just lists of characters, so we can just tell\n",
    "it to give us the characters between two numbered index positions. Like the\n",
    "range() function, the character at the first position is included, but the second\n",
    "number is not. Also recall that Python starts counting lists of items at zero (often\n",
    "called zero-indexing). This means that for each entry, the first number will be one\n",
    "less than whatever the metadata says, but the righthand number will be the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Based Data—Web-Driven Live Updates <br><br>\n",
    "With the rise of the internet, however,came the need to transmit large quantities of the type of “free” text found in, for example, news stories and social media feeds. Because this type of data content typically includes characters like commas, periods, and quotation marks that affect its semantic meaning, fitting it into a traditional delimited format will be problematic at best. What’s more, the horizontal bias of delimited formats (which involves lots of left-right scrolling) runs counter to the vertical-scrolling conventions of the web. Feed-based data formats have been designed to address both of these limitations. \n",
    "At a high level, there are two main types of feed-based data formats: XML and JSON.\n",
    "Both are text-based formats that allow the data provider to define their own unique\n",
    "data structure, making them extremely flexible and, consequently, useful for the wide\n",
    "variety of content found on internet-connected websites and platforms. Whether\n",
    "they’re located online or you save a copy locally, you’ll recognize these formats, in\n",
    "part, by their coordinating .xml and .json file extensions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4-12. xml_parsing.py\n",
    "\n",
    "# an example of reading data from an .xml file with Python, using the \"lxml\"\n",
    "# library.\n",
    "# first, you'll need to pip install the lxml library:\n",
    "# https://pypi.org/project/lxml/\n",
    "# a helpful tutorial can be found here: https://lxml.de/tutorial.html\n",
    "# the data used here is an instance of\n",
    "# https://api.stlouisfed.org/fred/series/observations?series_id=U6RATE& \\\n",
    "# api_key=YOUR_API_KEY_HERE\n",
    "# specify the \"chapter\" of the `lxml` library you want to import, in this case, `etree`, which stands for \"ElementTree\"\n",
    "\n",
    "from lxml import etree\n",
    "# import the `csv` library, to create our output file\n",
    "import csv\n",
    "# choose a filename\n",
    "filename = \"U6_FRED_data\"\n",
    "# open our data file in read format, using \"rb\" as the \"mode\"\n",
    "xml_source_file = open(filename+\".xml\",\"rb\")\n",
    "# pass our xml_source_file as an ingredient to the `lxml` library's\n",
    "# `etree.parse()` method and store the result in a variable called `xml_doc`\n",
    "xml_doc = etree.parse(xml_source_file)\n",
    "# start by getting the current xml document's \"root\" element\n",
    "document_root = xml_doc.getroot()\n",
    "# let's print it out to see what it looks like\n",
    "print(etree.tostring(document_root))\n",
    "# confirm that `document_root` is a well-formed XML element\n",
    "if etree.iselement(document_root):\n",
    "    # create our output file, naming it \"xml_\"+filename+\".csv\n",
    "    output_file = open(\"xml_\"+filename+\".csv\",\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
